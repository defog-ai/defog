{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defog Quick Start Demo (15 minutes)\n",
    "\n",
    "Welcome to the defog-python library! This notebook demonstrates the core capabilities:\n",
    "- Chat with multiple LLM providers using a unified interface\n",
    "- Extract structured data from PDFs and images\n",
    "- Query databases with natural language\n",
    "- Use agents for complex reasoning tasks\n",
    "\n",
    "**Time:** ~15 minutes | **Level:** Beginner | **Prerequisites:** API keys for at least one provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's install defog-python and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install defog-python (uncomment if not already installed)\n",
    "# !pip install defog-python[all]\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import display, Markdown, HTML, Image\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import defog components\n",
    "from defog.llm.utils import chat_async\n",
    "from defog.llm.pdf_data_extractor import PDFDataExtractor\n",
    "from defog.llm.image_data_extractor import ImageDataExtractor\n",
    "from defog.llm.sql import sql_answer_tool\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure API Keys\n",
    "\n",
    "Set up your API keys. You only need one provider to get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available providers: ['openai', 'anthropic', 'gemini']\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Set environment variables (recommended)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key\"\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-anthropic-key\"\n",
    "# os.environ[\"GEMINI_API_KEY\"] = \"your-gemini-key\"\n",
    "\n",
    "# Option 2: Load from .env file\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "# Check which providers are available\n",
    "available_providers = []\n",
    "for provider in [\"OPENAI\", \"ANTHROPIC\", \"GEMINI\"]:\n",
    "    if os.getenv(f\"{provider}_API_KEY\"):\n",
    "        available_providers.append(provider.lower())\n",
    "\n",
    "print(f\"Available providers: {available_providers}\")\n",
    "if not available_providers:\n",
    "    print(\"⚠️  No API keys found! Please set at least one provider's API key above.\")\n",
    "else:\n",
    "    default_provider = available_providers[0]\n",
    "    default_api_key = os.getenv(f\"{default_provider.upper()}_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple Chat - Unified LLM Interface\n",
    "\n",
    "The `chat_async` function provides a unified interface for all LLM providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Response:** Large Language Models (LLMs) like GPT-4 offer several compelling benefits for data analysis:\n",
       "\n",
       "1. **Natural Language Interaction**  \n",
       "   - **Query Data in Plain English:** LLMs let users ask questions about data using natural language, reducing the need to write complex queries or code.\n",
       "   - **Lower Barrier to Entry:** Non-technical users can analyze data without deep knowledge of programming or statistics.\n",
       "\n",
       "2. **Automated Data Processing**  \n",
       "   - **Data Cleaning & Transformation:** LLMs can help identify inconsistencies, suggest corrections, and automate cleaning steps.\n",
       "   - **Data Summarization:** They quickly summarize large, complex datasets or reports, highlighting trends and anomalies.\n",
       "\n",
       "3. **Insight Generation**  \n",
       "   - **Pattern Recognition:** LLMs can surface non-obvious patterns or correlations in data.\n",
       "   - **Hypothesis Generation:** They can suggest potential hypotheses or follow-up analyses based on data context.\n",
       "\n",
       "4. **Code Generation & Assistance**  \n",
       "   - **Automate Analysis Scripts:** LLMs generate Python, R, SQL, or other code snippets for tasks like visualization, statistical tests, or machine learning.\n",
       "   - **Debugging Help:** They assist in troubleshooting code or suggesting improvements.\n",
       "\n",
       "5. **Visualization Support**  \n",
       "   - **Chart Recommendations:** LLMs can propose appropriate charts/graphs for various data types and generate code to create them.\n",
       "   - **Interpretation of Visuals:** They help explain what a chart or graph means in plain language.\n",
       "\n",
       "6. **Documentation & Reporting**  \n",
       "   - **Auto-generate Reports:** LLMs can draft executive summaries, reports, or presentations based on analysis results.\n",
       "   - **Explain Methods:** They document analytical steps, making results more transparent and reproducible.\n",
       "\n",
       "7. **Scalability & Accessibility**  \n",
       "   - **Handle Large Volumes:** LLMs can help process and interpret vast datasets efficiently.\n",
       "   - **Integration:** They can be integrated into business intelligence tools, chatbots, and dashboards for real-time assistance.\n",
       "\n",
       "**Limitations to Remember:**  \n",
       "- LLMs may hallucinate or misinterpret data if not provided with clear, structured input.\n",
       "- They often require coupling with dedicated data processing tools for handling raw or very large datasets.\n",
       "\n",
       "**Summary:**  \n",
       "LLMs democratize data analysis by improving accessibility, automating routine tasks, and speeding up the process of insight generation, making data-driven decision-making more efficient and inclusive."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple chat example\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What are the main benefits of using LLMs for data analysis?\",\n",
    "    }\n",
    "]\n",
    "\n",
    "response = await chat_async(\n",
    "    messages=messages,\n",
    "    provider=\"openai\",\n",
    "    model=\"gpt-4.1\",\n",
    "    temperature=0.7,\n",
    "    max_completion_tokens=1000,\n",
    ")\n",
    "\n",
    "display(Markdown(f\"**Response:** {response.content}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Structured Output with Pydantic\n",
    "\n",
    "Get structured, validated responses using Pydantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>topic</th>\n",
       "      <th>insight</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Explosive Batting &amp; Depth</td>\n",
       "      <td>Teams with strong batting depth that can accelerate scoring in the middle and death overs, along with a solid opening partnership, consistently post winning totals or chase targets effectively.</td>\n",
       "      <td>High scores put immense pressure on the opposition, while effective chases demonstrate composure and power-hitting, both vital for limited-overs success.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Wicket-Taking Bowling &amp; Variations</td>\n",
       "      <td>The ability of bowlers to take wickets at regular intervals, particularly through effective variations (pace, spin, slower balls), prevents opposition partnerships from flourishing and restricts run flow.</td>\n",
       "      <td>Wickets are the primary way to control the game and limit the opposition's score, crucial for both setting and chasing targets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Exceptional Fielding &amp; Catching</td>\n",
       "      <td>Elite fielding units that save crucial runs, execute run-outs, and hold onto difficult catches significantly impact match outcomes by creating pressure and removing key batsmen.</td>\n",
       "      <td>Every run saved and every wicket taken through fielding directly contributes to the team's total or limits the opponent's, often turning close matches in their favor.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a structured output format\n",
    "class CricketInsight(BaseModel):\n",
    "    topic: str = Field(description=\"Aspect of cricket being analyzed\")\n",
    "    insight: str = Field(description=\"Key insight or finding\")\n",
    "    relevance: str = Field(description=\"Why this matters\")\n",
    "\n",
    "\n",
    "class CricketAnalysis(BaseModel):\n",
    "    insights: List[CricketInsight] = Field(description=\"List of cricket insights\")\n",
    "\n",
    "\n",
    "# Get structured response\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What are 3 key factors that contribute to winning matches in limited overs cricket?\",\n",
    "    }\n",
    "]\n",
    "\n",
    "analysis = await chat_async(\n",
    "    messages=messages,\n",
    "    provider=\"gemini\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    response_format=CricketAnalysis,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Display as a nice table\n",
    "df = pd.DataFrame([insight.model_dump() for insight in analysis.content.insights])\n",
    "display(HTML(df.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Natural Language Database Queries - Cricket World Cup 2015\n",
    "\n",
    "Query the Cricket World Cup database using natural language!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tables: ['ball_by_ball', 'match_summary', 'player_batting_stats', 'player_bowling_stats', 'team_performance']\n"
     ]
    }
   ],
   "source": [
    "# Connect to the cricket database\n",
    "db_conn = duckdb.connect(\"../sample_data/cricket_wc2015.duckdb\")\n",
    "\n",
    "# See what tables we have\n",
    "tables = db_conn.execute(\"SHOW TABLES\").fetchall()\n",
    "print(f\"Available tables: {[t[0] for t in tables]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">─────────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">🔧 SQL Query Answer</span><span style=\"color: #008080; text-decoration-color: #008080\"> ───────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m─────────────────────────────────────────────── \u001b[0m\u001b[1;36m🔧 SQL Query Answer\u001b[0m\u001b[36m ───────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Answering: Who were the top 5 run scorers in the tournament?</span>                                                   <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mAnswering: Who were the top 5 run scorers in the tournament?\u001b[0m                                                   \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Provider: </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">anthropic</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> | Model: </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">claude-sonnet-</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">4</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">-</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">20250514</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[2mProvider: \u001b[0m\u001b[1;2manthropic\u001b[0m\u001b[2m | Model: \u001b[0m\u001b[1;2mclaude-sonnet-\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m-\u001b[0m\u001b[1;2;36m20250514\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  ⚡ <span style=\"color: #008080; text-decoration-color: #008080\">Extracting table metadata</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  ⚡ \u001b[36mExtracting table metadata\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting schema for each table that you selected...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting schema for each table that you selected...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  ⚡ <span style=\"color: #008080; text-decoration-color: #008080\">Converting question to SQL</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  ⚡ \u001b[36mConverting question to SQL\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  ⚡ <span style=\"color: #008080; text-decoration-color: #008080\">Running query on database</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  ⚡ \u001b[36mRunning query on database\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Completed in </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">6.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8s</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mCompleted in \u001b[0m\u001b[1;2;36m6.\u001b[0m\u001b[2m8s\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL: SELECT batsman_name, runs_scored\n",
      "FROM player_batting_stats\n",
      "ORDER BY runs_scored DESC\n",
      "LIMIT 5;\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batsman_name</th>\n",
       "      <th>runs_scored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Martin Guptill</td>\n",
       "      <td>547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kumar Sangakkara</td>\n",
       "      <td>541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB de Villiers</td>\n",
       "      <td>482.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brendan Taylor</td>\n",
       "      <td>433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shikhar Dhawan</td>\n",
       "      <td>412.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       batsman_name  runs_scored\n",
       "0    Martin Guptill        547.0\n",
       "1  Kumar Sangakkara        541.0\n",
       "2    AB de Villiers        482.0\n",
       "3    Brendan Taylor        433.0\n",
       "4    Shikhar Dhawan        412.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query 1: Top run scorers\n",
    "result = await sql_answer_tool(\n",
    "    question=\"Who were the top 5 run scorers in the tournament?\",\n",
    "    db_type=\"duckdb\",\n",
    "    db_creds={\n",
    "        \"database\": \"/Users/rishabh/defog/defog-python/sample_data/cricket_wc2015.duckdb\"\n",
    "    },\n",
    "    provider=\"anthropic\",\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    ")\n",
    "\n",
    "if result[\"success\"]:\n",
    "    print(f\"Generated SQL: {result['query']}\\n\")\n",
    "    df = pd.DataFrame(result[\"results\"], columns=result[\"columns\"])\n",
    "    display(df)\n",
    "else:\n",
    "    print(f\"Error: {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. PDF Data Extraction - Apple Financials\n",
    "\n",
    "Extract structured data from PDF documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Extracting data from Apple's financial report..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Type: unknown\n",
      "Total datapoints identified: 0\n",
      "Successful extractions: 0\n",
      "Failed extractions: 0\n",
      "Total time: 6.34 seconds\n",
      "\n",
      "--- Cost Analysis ---\n",
      "Total cost: $0.0274\n",
      "Analysis cost (Step 1): $0.0274\n",
      "Extraction cost (Step 2+): $0.0000\n",
      "\n",
      "--- Token Usage ---\n",
      "Total input tokens: 1,174\n",
      "Total output tokens: 130\n",
      "Total cached tokens: 0\n",
      "Total tokens: 1,304\n",
      "\n",
      "--- Extracted Datapoints ---\n"
     ]
    }
   ],
   "source": [
    "# Initialize PDF extractor\n",
    "pdf_extractor = PDFDataExtractor(\n",
    "    analysis_provider=\"anthropic\",\n",
    "    analysis_model=\"claude-opus-4-20250514\",\n",
    "    extraction_provider=\"anthropic\",\n",
    "    extraction_model=\"claude-opus-4-20250514\",\n",
    "    max_parallel_extractions=10,\n",
    ")\n",
    "\n",
    "# Extract data\n",
    "display(Markdown(\"### Extracting data from Apple's financial report...\"))\n",
    "\n",
    "result = await pdf_extractor.extract_all_data(\n",
    "    pdf_url=\"https://www.apple.com/newsroom/pdfs/fy2025-q2/FY25_Q2_Consolidated_Financial_Statements.pdf\",\n",
    ")\n",
    "\n",
    "print(f\"\\nDocument Type: {result.document_type}\")\n",
    "print(f\"Total datapoints identified: {result.total_datapoints_identified}\")\n",
    "print(f\"Successful extractions: {result.successful_extractions}\")\n",
    "print(f\"Failed extractions: {result.failed_extractions}\")\n",
    "print(f\"Total time: {result.total_time_ms / 1000:.2f} seconds\")\n",
    "\n",
    "print(\"\\n--- Cost Analysis ---\")\n",
    "print(f\"Total cost: ${result.total_cost_cents / 100:.4f}\")\n",
    "print(\n",
    "    f\"Analysis cost (Step 1): ${result.metadata.get('analysis_cost_cents', 0.0) / 100:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Extraction cost (Step 2+): ${result.metadata.get('extraction_cost_cents', 0.0) / 100:.4f}\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- Token Usage ---\")\n",
    "print(f\"Total input tokens: {result.metadata.get('total_input_tokens', 0):,}\")\n",
    "print(f\"Total output tokens: {result.metadata.get('total_output_tokens', 0):,}\")\n",
    "print(f\"Total cached tokens: {result.metadata.get('total_cached_tokens', 0):,}\")\n",
    "print(\n",
    "    f\"Total tokens: {result.metadata.get('total_input_tokens', 0) + result.metadata.get('total_output_tokens', 0):,}\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- Extracted Datapoints ---\")\n",
    "for extraction in result.extraction_results:\n",
    "    if extraction.success:\n",
    "        print(f\"\\n✅ {extraction.datapoint_name}:\")\n",
    "        print(\n",
    "            f\"   Cost: ${extraction.cost_cents / 100:.4f} | Tokens: {extraction.input_tokens + extraction.output_tokens:,} (in:{extraction.input_tokens:,}, out:{extraction.output_tokens:,}, cached:{extraction.cached_tokens:,})\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"\\n❌ {extraction.datapoint_name}: {extraction.error}\")\n",
    "        if extraction.cost_cents > 0:\n",
    "            print(\n",
    "                f\"   Cost: ${extraction.cost_cents / 100:.4f} | Tokens: {extraction.input_tokens + extraction.output_tokens:,}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Image Data Extraction - Carbon Budget Visualization\n",
    "\n",
    "Extract data from charts and visualizations in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Carbon Budget Visualization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://ourworldindata.org/cdn-cgi/imagedelivery/qLq-8BTgXU8yG0N6HnOy8g/1cea1569-d611-4d7f-7a9c-d01f81fab400/w=5671\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the image\n",
    "display(Markdown(\"### Carbon Budget Visualization\"))\n",
    "display(\n",
    "    Image(\n",
    "        url=\"https://ourworldindata.org/cdn-cgi/imagedelivery/qLq-8BTgXU8yG0N6HnOy8g/1cea1569-d611-4d7f-7a9c-d01f81fab400/w=5671\",\n",
    "        width=600,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_url='https://ourworldindata.org/cdn-cgi/imagedelivery/qLq-8BTgXU8yG0N6HnOy8g/1cea1569-d611-4d7f-7a9c-d01f81fab400/w=5671' image_type='infographic' total_datapoints_identified=2 successful_extractions=2 failed_extractions=0 extraction_results=[DataExtractionResult(datapoint_name='carbon_budget_for_1_5c', success=True, extracted_data=carbon_budget_for_1_5c(columns=['category', 'co2_billion_tonnes'], data=[['17%', 500], ['33%', 300], ['50%', 250], ['67%', 150], ['83%', 100], ['Global emissions 2022', 41]], chart_type='bar', row_count=6), error=None, cost_cents=2.797, input_tokens=1421, output_tokens=344, cached_tokens=0), DataExtractionResult(datapoint_name='carbon_budget_for_2c', success=True, extracted_data=carbon_budget_for_2c(columns=['category', 'co2_billion_tonnes'], data=[['17%', 2000], ['33%', 1450], ['50%', 1150], ['67%', 950], ['83%', 800], ['Global emissions 2022', 41]], chart_type='bar', row_count=6), error=None, cost_cents=2.791, input_tokens=1411, output_tokens=345, cached_tokens=0)] total_time_ms=30678 total_cost_cents=10.457 metadata={'content_description': 'Infographic with two side-by-side bar charts showing the remaining carbon budget (in billion tonnes of CO₂) for keeping global warming below 1.5 °C and 2 °C at different likelihood levels, plus a reference bar for global CO₂ emissions in 2022.', 'filtered_datapoints': 2, 'schemas_generated': 2, 'total_input_tokens': 4737, 'total_output_tokens': 1430, 'total_cached_tokens': 0, 'analysis_cost_cents': 4.869, 'extraction_cost_cents': 5.588000000000001}\n"
     ]
    }
   ],
   "source": [
    "# Initialize image extractor\n",
    "image_extractor = ImageDataExtractor(\n",
    "    analysis_provider=\"openai\",\n",
    "    analysis_model=\"o3\",\n",
    "    extraction_provider=\"openai\",\n",
    "    extraction_model=\"o3\",\n",
    ")\n",
    "\n",
    "# Extract data from image\n",
    "carbon_data = await image_extractor.extract_all_data(\n",
    "    image_url=\"https://ourworldindata.org/cdn-cgi/imagedelivery/qLq-8BTgXU8yG0N6HnOy8g/1cea1569-d611-4d7f-7a9c-d01f81fab400/w=5671\",\n",
    ")\n",
    "\n",
    "# Display extracted data\n",
    "print(carbon_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# port over example from examples/orchestrator_dynamic_example.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "Congratulations! You've explored the core capabilities of defog-python:\n",
    "\n",
    "✅ **Unified LLM Interface** - Switch between providers with one line  \n",
    "✅ **Structured Output** - Get validated data with Pydantic models  \n",
    "✅ **Natural Language SQL** - Query databases conversationally  \n",
    "✅ **PDF Extraction** - Extract structured data from documents  \n",
    "✅ **Image Analysis** - Extract data from charts and visualizations  \n",
    "✅ **Thinking Agent** - Complex reasoning with transparent process  \n",
    "✅ **Orchestrator** - Multi-agent collaboration for complex tasks  \n",
    "\n",
    "### What's Next?\n",
    "\n",
    "1. **Deep Dive Tutorial** (Notebook 2) - Advanced features:\n",
    "   - Memory management for long conversations\n",
    "   - Custom tools and function calling\n",
    "   - Advanced extraction with HTML and text\n",
    "   - Building production pipelines\n",
    "\n",
    "2. **Production Patterns** (Notebook 3) - Best practices:\n",
    "   - Error handling and retries\n",
    "   - Cost optimization\n",
    "   - Performance tuning\n",
    "   - Security considerations\n",
    "\n",
    "### Try These Challenges:\n",
    "\n",
    "- Extract data from your own PDFs or images\n",
    "- Create custom Pydantic schemas for your use case\n",
    "- Build a data pipeline combining multiple sources\n",
    "- Compare provider performance on your specific tasks\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- Documentation: [defog.ai/docs](https://defog.ai/docs)\n",
    "- GitHub: [github.com/defog-ai/defog-python](https://github.com/defog-ai/defog-python)\n",
    "- Support: support@defog.ai\n",
    "\n",
    "Happy building! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
