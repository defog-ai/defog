# LLM Utilities Documentation

This directory contains detailed documentation for all LLM-related functionality in the defog library.

## Core Features

- [Core Chat Functions](core-chat-functions.md) - Unified interface for multiple LLM providers
- [Multimodal Support](multimodal-support.md) - Image inputs across all providers
- [Function Calling](function-calling.md) - Define tools for LLMs with automatic schema generation
- [Structured Output](structured-output.md) - Get validated responses using Pydantic models

## Advanced Features

- [Memory Management](memory-management.md) - Handle long conversations with automatic summarization
- [Tool Budget Management](tool-budget-management.md) - Limit tool usage to control costs
- [Tool Citations](tool-citations.md) - Automatic citation addition for tool outputs
- [Cost Tracking](cost-tracking.md) - Track and monitor LLM operation costs

## Specialized Tools

- [Code Interpreter](code-interpreter.md) - Execute Python code in sandboxed environments
- [Web Search](web-search.md) - AI-powered web search integration
- [YouTube Transcription](youtube-transcription.md) - Video summarization and transcription
- [Citations Tool](citations-tool.md) - Generate cited answers from documents
- [MCP Integration](mcp-integration.md) - Model Context Protocol server integration

## Guidelines

- [Best Practices](best-practices.md) - Recommendations for optimal library usage